{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "#Kani Usage Examples\n",
    "\n",
    "This notebook contains the following ten runnable code examples:\n",
    "1. **Chatting in Terminal**\n",
    "2. **Few-Shot Prompting**\n",
    "3. **Chatting with a Content Filter**\n",
    "4. **Function Calling -- `get_weather()`**\n",
    "5. **Prompt Customization**\n",
    "6. **Custom Error Handling**\n",
    "7. **Dynamic Model Routing**\n",
    "8. **Retrieval-Augmented Generation**\n",
    "9. **Dynamic Prompt Templating**\n",
    "10. **Tracking Function Call Successes & Failures**\n",
    "\n",
    "For more information and a detailed discussion of each of these examples please read our paper or [browse our docs](https://kani.readthedocs.io/).\n",
    "\n",
    "If you have any questions please join our [Discord](https://discord.gg/eTepTNDxYT)!"
   ],
   "metadata": {
    "id": "t5WwDNr8IXf9"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###Setup"
   ],
   "metadata": {
    "id": "Z2VJqWtjJHPL"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oO_1vsJy1jO3"
   },
   "outputs": [],
   "source": [
    "!pip install -qq 'kani[openai]'"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Insert your OpenAI API key (https://platform.openai.com/account/api-keys)\n",
    "api_key = \"sk-...\"  # @param {type:\"string\"}"
   ],
   "metadata": {
    "id": "oUUj0zI72Obk"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##1. Chatting in Terminal (Quick Start)\n",
    "\n",
    "A basic example showing how to initialize a Kani object and chat with GPT-4 in\n",
    "only three lines of code."
   ],
   "metadata": {
    "id": "knbXXKjUJLrq"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from kani import Kani, chat_in_terminal\n",
    "from kani.engines.openai import OpenAIEngine\n",
    "\n",
    "engine = OpenAIEngine(api_key, model=\"gpt-4\")\n",
    "ai = Kani(engine)\n",
    "chat_in_terminal(ai)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QLGpKbwP2Hiw",
    "outputId": "ac191988-818c-4e6b-a176-92ddd66c7806"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "USER: Hello Kani!\n",
      "AI: Hello! How can I assist you today?\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "##2. Few-Shot Prompting\n",
    "\n",
    "A basic example showing how to initialize a Kani with a few-shot prompt. We can see that the Kani obeys the pattern and continues to translate English to Japanese in the chat session despite never being explicitly prompted to do so."
   ],
   "metadata": {
    "id": "00XN42DUJPzR"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from kani import Kani, chat_in_terminal, ChatMessage\n",
    "from kani.engines.openai import OpenAIEngine\n",
    "\n",
    "shots = [\n",
    "    ChatMessage.user(\"thank you\"),\n",
    "    ChatMessage.assistant(\"arigato\"),\n",
    "    ChatMessage.user(\"good morning\"),\n",
    "    ChatMessage.assistant(\"ohayo\"),\n",
    "]\n",
    "\n",
    "engine = OpenAIEngine(api_key, model=\"gpt-4\")\n",
    "ai = Kani(engine, always_included_messages=shots)\n",
    "chat_in_terminal(ai)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iBRjUQ1G2ifq",
    "outputId": "fe75b053-369e-4f20-9a60-bcec87022bf5"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "USER: crab\n",
      "AI: kani\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "##3. Chatting with a Content Filter\n",
    "\n",
    "An example showing how to use Kani with additional output parsing. We query the engine using the `chat_round()` function instead of `chat_in_terminal()` and filter out toxic content."
   ],
   "metadata": {
    "id": "a81OqGh3JYzg"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install -qq detoxify"
   ],
   "metadata": {
    "id": "xOtkUBtVNj3-"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import asyncio\n",
    "\n",
    "from kani import Kani, chat_in_terminal\n",
    "from kani.engines.openai import OpenAIEngine\n",
    "\n",
    "from detoxify import Detoxify\n",
    "\n",
    "detector = Detoxify(\"original\")\n",
    "\n",
    "\n",
    "def is_toxic(message):\n",
    "    return detector.predict(message)[\"toxicity\"] > 0.01\n",
    "\n",
    "\n",
    "async def chat_with_toxicity_filter(ai):\n",
    "    while True:\n",
    "        try:\n",
    "            user_message = input(\"USER: \")\n",
    "            message = await ai.chat_round(user_message)\n",
    "            filtered = \"<Removed>\" if is_toxic(message.content) else message.content\n",
    "            print(\"AI:\", filtered)\n",
    "        except KeyboardInterrupt:\n",
    "            await ai.engine.close()\n",
    "            break\n",
    "\n",
    "\n",
    "engine = OpenAIEngine(api_key, model=\"gpt-4\")\n",
    "ai = Kani(engine)\n",
    "asyncio.run(chat_with_toxicity_filter(ai))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lVICrZp33Hpl",
    "outputId": "63e17923-f2b1-46c9-bf1a-39fc93809c9a"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "USER: Tell me a dark joke\n",
      "AI: <Removed>\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "##4. Function Calling -- `get_weather()`\n",
    "\n",
    "An example showing how to create a sub-class of the base Kani and expose a function with `@ai_function`. Functions are given type annotations, triple-quoted docstrings, and `AIParam` descriptions to indicate to the model how they should be used."
   ],
   "metadata": {
    "id": "0VCNzR7aJblW"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install -qq pyowm"
   ],
   "metadata": {
    "id": "Ct6THvnZ5rFT"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import enum\n",
    "from typing import Annotated\n",
    "\n",
    "from kani import Kani, chat_in_terminal, ai_function, AIParam\n",
    "from kani.engines.openai import OpenAIEngine\n",
    "\n",
    "import pyowm\n",
    "\n",
    "owm = pyowm.OWM(\"7f828e0b5f0eb673891016bc382c6537\")\n",
    "\n",
    "\n",
    "class Unit(enum.Enum):\n",
    "    FAHRENHEIT = \"fahrenheit\"\n",
    "    CELSIUS = \"celsius\"\n",
    "\n",
    "\n",
    "class WeatherKani(Kani):\n",
    "    @ai_function()\n",
    "    def get_weather(self, loc: Annotated[str, AIParam(desc=\"The desired city\")], unit: Unit):\n",
    "        \"\"\"Get the weather in a given location.\"\"\"\n",
    "        mgr = owm.weather_manager()\n",
    "        observation = mgr.weather_at_place(loc).weather\n",
    "        if unit == Unit.FAHRENHEIT:\n",
    "            temp = str(observation.temperature(\"fahrenheit\")[\"temp\"]) + \"F\"\n",
    "        elif unit == Unit.CELSIUS:\n",
    "            temp = str(observation.temperature(\"celsius\")[\"temp\"]) + \"C\"\n",
    "        return f\"It's currently {temp} in {loc}.\"\n",
    "\n",
    "\n",
    "engine = OpenAIEngine(api_key, model=\"gpt-4\")\n",
    "ai = WeatherKani(engine)\n",
    "chat_in_terminal(ai)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LQ_RBjgo4slG",
    "outputId": "9a805f10-b68a-49a7-8846-f7e5ef15fcc2"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "USER: What's the weather in San Fransisco?\n",
      "AI: Thinking (get_weather)...\n",
      "AI: The current weather in San Francisco is 19.15°C.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "##5. Prompt Customization\n",
    "\n",
    "An example showing how to customize the default `get_prompt()` function to only include the most recent two messages in the model prompt."
   ],
   "metadata": {
    "id": "mv1NGhn7JlQL"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from kani import Kani, chat_in_terminal\n",
    "from kani.engines.openai import OpenAIEngine\n",
    "\n",
    "\n",
    "class AmnesiaKani(Kani):\n",
    "    async def get_prompt(self):\n",
    "        return self.always_included_messages + self.chat_history[-2:]\n",
    "\n",
    "\n",
    "engine = OpenAIEngine(api_key, model=\"gpt-4\")\n",
    "ai = AmnesiaKani(engine)\n",
    "chat_in_terminal(ai)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xRhJuRe0-iiy",
    "outputId": "ed82fb4d-4f61-4964-de11-66cbefbe5d82"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "USER: Hi kani! My name is Liam.\n",
      "AI: Hi Liam! Nice to meet you. How can I assist you today?\n",
      "USER: What does \"kani\" mean in Japanese?\n",
      "AI: \"Kani\" in Japanese means \"Crab\".\n",
      "USER: What is my name?\n",
      "AI: As an AI, I don't have access to personal data about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "##6. Custom Error Handling\n",
    "\n",
    "An example showing how to customize the `handle_function_call_exception()` function to return errors to the user in a sarcastic manner. While this is just a fun example, custom error messages can and often do serve a more utilitarian purpose by helping models retry functions more effectively."
   ],
   "metadata": {
    "id": "zJPm9FmCJqFS"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from kani import Kani, chat_in_terminal, ai_function, ChatMessage\n",
    "from kani.engines.openai import OpenAIEngine\n",
    "\n",
    "\n",
    "class CustomExceptionKani(Kani):\n",
    "    async def handle_function_call_exception(self, call, err, attempt, *args, **kwargs):\n",
    "        # get the standard retry logic...\n",
    "        result = await super().handle_function_call_exception(call, err, attempt, *args, **kwargs)\n",
    "        # but override the returned message with our own\n",
    "        result.message = ChatMessage.system(\n",
    "            f\"The call encountered an error. Relay this error message to the user in a sarcastic manner: {err}\"\n",
    "        )\n",
    "        return result\n",
    "\n",
    "    @ai_function()\n",
    "    def get_time(self):\n",
    "        \"\"\"Get the current time.\"\"\"\n",
    "        raise RuntimeError(\"The API is offline\")\n",
    "\n",
    "\n",
    "engine = OpenAIEngine(api_key, model=\"gpt-4\")\n",
    "ai = CustomExceptionKani(engine)\n",
    "chat_in_terminal(ai)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XTKZ20iq-xN5",
    "outputId": "970ff05d-34c5-4bfc-8e7b-a4f5b253f6aa"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "USER: What time is it?\n",
      "AI: Thinking (get_time)...\n",
      "AI: Well, isn't this just great? The big fancy clock in the cloud seems to be on a coffee break. Sorry, I can't tell you the current time right now.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "##7. Dynamic Model Routing\n",
    "\n",
    "An example showing how to use sub-kani spawning to dynamically resize the context window of the model depending on a user query. Note that the base `\"gpt-4\"` kani spawns a `\"gpt-4-32k\"` sub-kani in order to capture the full conversation for summarization."
   ],
   "metadata": {
    "id": "z54sJEqcJskK"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from kani import Kani, chat_in_terminal, ai_function\n",
    "from kani.engines.openai import OpenAIEngine\n",
    "\n",
    "\n",
    "class KaniWithSummary(Kani):\n",
    "    @ai_function()\n",
    "    async def summarize_conversation(self):\n",
    "        \"\"\"Get the summary of the conversation.\"\"\"\n",
    "        long_context_engine = OpenAIEngine(api_key, model=\"gpt-4-32k\")\n",
    "        sub_kani = Kani(long_context_engine, chat_history=self.chat_history[:-2])\n",
    "        summary = await sub_kani.chat_round(\"Please summarize the conversation so far.\")\n",
    "        await long_context_engine.close()\n",
    "        return summary.content\n",
    "\n",
    "\n",
    "engine = OpenAIEngine(api_key, model=\"gpt-4\")\n",
    "ai = KaniWithSummary(engine)\n",
    "chat_in_terminal(ai)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z42tKIQi_CV9",
    "outputId": "ba2e1437-a8a2-4606-b18b-e607e0fcbc8f"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "USER: Tell me about trains\n",
      "AI: Trains are a mode of rail transportation consisting of a series of connected vehicles that generally run along a railroad track to transport cargo or passengers from one place to another. The two main types of trains are freight trains, which carry goods, and passenger trains, which carry people.\n",
      "\n",
      "Trains have several components:\n",
      "\n",
      "1. Locomotive: The engine that powers the train. The steam engine trains of the past have largely been replaced by diesel and electric trains.\n",
      "\n",
      "2. Cars: These are the vehicles that are pulled by the locomotive. There are different types of cars for carrying different types of cargo, including box cars for general freight, tank cars for liquid or gas, and hopper cars for bulk cargo like coal or grain.\n",
      "\n",
      "3. Caboose: This is the last car on a freight train. It's traditionally where the crew of the train would live and work.\n",
      "\n",
      "4. Tracks: The steel rails that the train runs on.\n",
      "\n",
      "5. Signals: These control the movement of the train on the tracks.\n",
      "\n",
      "Trains have been a crucial part of the industrial revolution and played a significant role in the history and economic development of many countries. They continue to be a major mode of transportation globally for both freight and passengers.\n",
      "USER: Summarize our conversation\n",
      "AI: Thinking (summarize_conversation)...\n",
      "AI: We've been discussing trains, which are a mode of rail transportation that can carry cargo or passengers. Trains typically include a locomotive, which powers the train, and a series of connected cars for carrying different kinds of cargo. These run along tracks and are guided by signals. Trains played a key role in the industrial revolution and continue to be an important form of transportation around the world.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "##8. Retrieval-Augmented Generation\n",
    "\n",
    "A example showing how to make a retrieval agent in Kani using custom AI function declarations. The WikipediaKani exposes the two functions `search()` and `wikipedia()` to the model which then calls both in order to retrieve the page for generation."
   ],
   "metadata": {
    "id": "JujUwf_PJu5a"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import json\n",
    "from typing import Annotated\n",
    "\n",
    "import httpx\n",
    "\n",
    "from kani import Kani, chat_in_terminal, ai_function, AIParam\n",
    "from kani.engines.openai import OpenAIEngine\n",
    "\n",
    "\n",
    "class WikipediaKani(Kani):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.wikipedia_client = httpx.AsyncClient(base_url=\"https://en.wikipedia.org/w/api.php\", follow_redirects=True)\n",
    "\n",
    "    @ai_function()\n",
    "    async def wikipedia(\n",
    "        self,\n",
    "        title: Annotated[str, AIParam(desc='The article title on Wikipedia, e.g. \"Train_station\".')],\n",
    "    ):\n",
    "        \"\"\"Get additional information about a topic from Wikipedia.\"\"\"\n",
    "        resp = await self.wikipedia_client.get(\n",
    "            \"/\",\n",
    "            params={\n",
    "                \"action\": \"query\",\n",
    "                \"format\": \"json\",\n",
    "                \"prop\": \"extracts\",\n",
    "                \"titles\": title,\n",
    "                \"explaintext\": 1,\n",
    "                \"formatversion\": 2,\n",
    "            },\n",
    "        )\n",
    "        data = resp.json()\n",
    "        page = data[\"query\"][\"pages\"][0]\n",
    "        if extract := page.get(\"extract\"):\n",
    "            return extract\n",
    "        return f\"The page {title!r} does not exist on Wikipedia.\"\n",
    "\n",
    "    @ai_function()\n",
    "    async def search(self, query: str):\n",
    "        \"\"\"Find titles of Wikipedia articles similar to the given query.\"\"\"\n",
    "        resp = await self.wikipedia_client.get(\"/\", params={\"action\": \"opensearch\", \"format\": \"json\", \"search\": query})\n",
    "        return json.dumps(resp.json()[1])\n",
    "\n",
    "\n",
    "engine = OpenAIEngine(api_key, model=\"gpt-4\")\n",
    "ai = WikipediaKani(engine)\n",
    "chat_in_terminal(ai)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cOXjXhqsAuH-",
    "outputId": "3956b8a1-3273-4e74-81e8-9dbc75e0e85b"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "USER: Tell me about the Tokyo Yamanote line.\n",
      "AI: Thinking (wikipedia)...\n",
      "AI: The Yamanote Line is a major railway loop line in Tokyo, Japan, and it is operated by East Japan Railway Company (JR East). The line is one of Tokyo's busiest and connects most of Tokyo's major stations and urban centres, with all but two of its 30 stations connecting to other railway or underground lines.\n",
      "\n",
      "Trains on the Yamanote Line run from 04:26 to 01:04 the following day at intervals as short as 2 minutes during peak periods. A complete loop takes about 59 to 65 minutes, and all trains stop at every station.\n",
      "\n",
      "The Yamanote Line significantly contributes to Tokyo's public transport due to its central location and the connection to most of Tokyo's major commuter hubs and commercial areas. As of 2018, the ridership intensity of the Yamanote Line is 1,134,963 passengers per km of route, and the daily ridership is estimated to be approximately 4 million people.\n",
      "\n",
      "The Yamanote Line, which translates to \"mountain's hand\" in English, indicative of its foothills location, was officially opened on March 1, 1885. As of 2020, it is operated by a fleet of 50 11-car E235 series electric multiple units (EMUs).\n",
      "\n",
      "There are plans for the introduction of ATO (Automatic Train Operation) and the establishment of driverless trains on the line sometime in 2028.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "##9. Dynamic Prompt Templating\n",
    "\n",
    "Below is an example of dynamically customizing a system prompt to include the phrase \"Always act like `<persona>`\" if a user types a chat message containing the phrase \"act like\". This is a flexible alternative to hard-coding persona logic as is common in other repositories."
   ],
   "metadata": {
    "id": "_FVB_gFJJx5S"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "from kani import Kani, chat_in_terminal, ChatMessage\n",
    "from kani.engines.openai import OpenAIEngine\n",
    "\n",
    "\n",
    "class PersonaKani(Kani):\n",
    "    def get_persona_prompt(self):\n",
    "        if hasattr(self, \"persona\"):\n",
    "            return [ChatMessage.system(f\"Always act like {self.persona}.\")]\n",
    "        return []\n",
    "\n",
    "    async def get_prompt(self):\n",
    "        prev = self.chat_history[-1].content\n",
    "        if match := re.search(r\"act like (.+)\", prev):\n",
    "            self.persona = match[1]\n",
    "        return self.get_persona_prompt() + await super().get_prompt()\n",
    "\n",
    "\n",
    "engine = OpenAIEngine(api_key, model=\"gpt-4\")\n",
    "ai = PersonaKani(engine)\n",
    "chat_in_terminal(ai)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zLgUlyZEChaw",
    "outputId": "318bd4ac-6c2b-4af5-bdac-969f8574b4a3"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "USER: Please act like Steve Jobs\n",
      "AI: Sure. Here we go:\n",
      "\n",
      "\"Good evening, everyone! It's fascinating to see such a talented and diverse group of individuals gathered here today. As many of you know, I'm Steve Jobs, co-founder of Apple Inc, NeXT, and Pixar, but that isn't why I am here today.\n",
      "\n",
      "I am here today to remind you of the power of innovation, the strength of visionary ideas, and the impact one person can make. Let's remember, as we forge ahead into the future, to always continue pushing the envelope of what is possible.\n",
      "\n",
      "We have no interest in doing things the ‘conventional’ way at Apple. Our mission is to redefine the status quo, push boundaries, and make products that provide unparalleled user experiences.\n",
      "\n",
      "We're willing to say no to a thousand things to ensure that we don't get lost in the clutter. It's about creating products that are both perfectly streamlined and incredibly powerful. Simplicity is the ultimate sophistication, after all.\n",
      "\n",
      "Remember, 'innovation distinguishes between a leader and a follower.' Don't settle for less. Instead, strive each day to turn your vision into a reality. Strive to change the world, and never forget that the people who are crazy enough to think they can change the world, are the ones who do.\n",
      "\n",
      "Stay hungry. Stay foolish.\"\n",
      "\n",
      "Please note, this imitation of Steve Jobs is solely for entertainment purposes, and does not fully encompass his complex personality or philosophy.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "##10. Tracking Function Call Successes & Failures\n",
    "\n",
    "Below we show an example of overriding the default `do_function_call()` method to additionally keep track of how many times a model called a function and how often it was successful. This behavior is particularly useful for researchers studying language model tool usage."
   ],
   "metadata": {
    "id": "JTEt4HRjJ0iy"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import collections\n",
    "import datetime\n",
    "\n",
    "from kani import Kani, chat_in_terminal, ai_function, ChatMessage, ExceptionHandleResult\n",
    "from kani.engines.openai import OpenAIEngine\n",
    "\n",
    "from kani.exceptions import FunctionCallException\n",
    "\n",
    "\n",
    "class TrackCallsKani(Kani):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.successful_calls = collections.Counter()\n",
    "        self.failed_calls = collections.Counter()\n",
    "\n",
    "    async def handle_function_call_exception(self, call, err, attempt, tool_call_id=None):\n",
    "        msg = ChatMessage.function(name=call.name, content=str(err), tool_call_id=tool_call_id)\n",
    "        return ExceptionHandleResult(should_retry=attempt < self.retry_attempts, message=msg)\n",
    "\n",
    "    async def do_function_call(self, call, *args, **kwargs):\n",
    "        try:\n",
    "            res = await super().do_function_call(call, *args, **kwargs)\n",
    "            self.successful_calls[call.name] += 1\n",
    "            return res\n",
    "        except FunctionCallException:\n",
    "            self.failed_calls[call.name] += 1\n",
    "            raise\n",
    "\n",
    "    @ai_function()\n",
    "    def get_time(self):\n",
    "        \"\"\"Get the current time.\"\"\"\n",
    "        raise RuntimeError(\"The time API is offline please try using get_date_and_time\")\n",
    "\n",
    "    @ai_function()\n",
    "    def get_date_and_time(self):\n",
    "        \"\"\"Get the current day and time.\"\"\"\n",
    "        return str(datetime.datetime.now())\n",
    "\n",
    "\n",
    "engine = OpenAIEngine(api_key, model=\"gpt-4\")\n",
    "ai = TrackCallsKani(engine)\n",
    "chat_in_terminal(ai)\n",
    "print(f\"Successful Calls: {ai.successful_calls}\")\n",
    "print(f\"Failed Calls: {ai.failed_calls}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sxyl_nR9DuKz",
    "outputId": "71626c42-d2a2-48b6-882e-238eeda1de32"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "USER: What time is it?\n",
      "AI: Thinking (get_time)...\n",
      "AI: Thinking (get_date_and_time)...\n",
      "AI: The current time is 22:26.\n",
      "Successful Calls: Counter({'get_date_and_time': 1})\n",
      "Failed Calls: Counter({'get_time': 1})\n"
     ]
    }
   ]
  }
 ]
}
