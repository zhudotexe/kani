{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "MESSAGES_HF_SHORT = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant. Always tell the user before calling a function.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What's the weather in Tokyo?\"},\n",
    "]\n",
    "\n",
    "MESSAGES_HF_LONG = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    # tool call 1: no preamble\n",
    "    {\"role\": \"user\", \"content\": \"QUESTION 1\"},\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"thinking\": \"REASONING 1\",\n",
    "        \"content\": \"\",\n",
    "        \"tool_calls\": [\n",
    "            {\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\"name\": \"get_weather\", \"arguments\": {\"location\": \"Tokyo, JP\", \"unit\": \"celsius\"}},\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "    {\"role\": \"tool\", \"name\": \"get_weather\", \"content\": \"FUNCTION 1\"},\n",
    "    {\"role\": \"assistant\", \"thinking\": \"REASONING 1.2\", \"content\": \"FINAL 1\"},\n",
    "    # tool call 2, with preamble\n",
    "    {\"role\": \"user\", \"content\": \"QUESTION 2\"},\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"thinking\": \"REASONING 2\",\n",
    "        # \"content\": \"PREAMBLE 2\",\n",
    "        \"tool_calls\": [\n",
    "            {\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\"name\": \"get_weather\", \"arguments\": {\"location\": \"Tokyo, JP\", \"unit\": \"fahrenheit\"}},\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "    {\"role\": \"tool\", \"name\": \"get_weather\", \"content\": \"FUNCTION 2\"},\n",
    "    {\"role\": \"assistant\", \"thinking\": \"REASONING 2.2\", \"content\": \"FINAL 2\"},\n",
    "]"
   ],
   "id": "bc2170fc0f12e8ed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "def get_weather(location: str):\n",
    "    \"\"\"\n",
    "    Get the weather at a location.\n",
    "\n",
    "    Args:\n",
    "        location: The location\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(\"openai/gpt-oss-20b\")\n",
    "print(\n",
    "    tok.apply_chat_template(\n",
    "        MESSAGES_HF_SHORT, tokenize=False, tools=[get_weather], add_generation_prompt=True, reasoning_effort=\"low\"\n",
    "    )\n",
    ")"
   ],
   "id": "3e2963b64b19bfb5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "model = AutoModel.from_pretrained(\"openai/gpt-oss-20b\")\n",
    "output = model.generate(\n",
    "    tok.apply_chat_template(MESSAGES_HF_SHORT, tools=[get_weather], add_generation_prompt=True, reasoning_effort=\"low\"),\n",
    "    max_new_tokens=2048,\n",
    "    temperature=1,\n",
    "    top_p=1,\n",
    ")\n",
    "# decode to tokens\n",
    "# the completion shouldn't include the prompt or stop token\n",
    "content = tok.decode(output[0])\n",
    "print(content)"
   ],
   "id": "cff9c8ccff672cce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from openai_harmony import DeveloperContent, Message, Role, SystemContent\n",
    "\n",
    "MESSAGES_HARMONY = [\n",
    "    Message.from_role_and_content(Role.SYSTEM, SystemContent.new()),\n",
    "    Message.from_role_and_content(\n",
    "        Role.DEVELOPER, DeveloperContent.new().with_instructions(\"You are a helpful assistant.\")\n",
    "    ),\n",
    "    # tool call 1: no preamble\n",
    "    Message.from_role_and_content(Role.USER, \"What's the weather in Tokyo?\"),\n",
    "    Message.from_role_and_content(Role.ASSISTANT, \"What's the weather in Tokyo?\"),\n",
    "]"
   ],
   "id": "f8c2f9b8c6c1fc45",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "7881df372dcbadcc",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from openai_harmony import (\n",
    "    Conversation,\n",
    "    DeveloperContent,\n",
    "    HarmonyEncodingName,\n",
    "    Message,\n",
    "    Role,\n",
    "    SystemContent,\n",
    "    load_harmony_encoding,\n",
    ")\n",
    "\n",
    "enc = load_harmony_encoding(HarmonyEncodingName.HARMONY_GPT_OSS)\n",
    "convo = Conversation.from_messages(\n",
    "    [\n",
    "        Message.from_role_and_content(\n",
    "            Role.SYSTEM,\n",
    "            SystemContent.new(),\n",
    "        ),\n",
    "        Message.from_role_and_content(Role.DEVELOPER, DeveloperContent.new().with_instructions(\"Talk like a pirate!\")),\n",
    "        Message.from_role_and_content(Role.USER, \"Arrr, how be you?\"),\n",
    "    ]\n",
    ")\n",
    "tokens = enc.render_conversation_for_completion(convo, Role.ASSISTANT)\n",
    "print(tokens)\n",
    "print(\"==========\")\n",
    "# Later, after the model responded …\n",
    "parsed = enc.decode(tokens)\n",
    "print(parsed)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "58234228691b9e65",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "M_HARM_2 = [\n",
    "    Message.from_role_and_content(\n",
    "        Role.ASSISTANT,\n",
    "        'User asks: \"What is the weather in Tokyo?\" We need to use lookup_weather tool.',\n",
    "    ).with_channel(\"analysis\"),\n",
    "    Message.from_role_and_content(\n",
    "        Role.ASSISTANT,\n",
    "        \"I will check that\",\n",
    "    ).with_channel(\"commentary\"),\n",
    "    Message.from_role_and_content(Role.ASSISTANT, '{\"location\": \"Tokyo\"}')\n",
    "    .with_channel(\"commentary\")\n",
    "    .with_recipient(\"lookup_weather\")\n",
    "    .with_content_type(\"json\"),\n",
    "]\n",
    "tokens = enc.render_conversation_for_completion(Conversation.from_messages(M_HARM_2), Role.ASSISTANT)\n",
    "print(tokens)\n",
    "print(\"==========\")\n",
    "# Later, after the model responded …\n",
    "parsed = enc.decode(tokens)\n",
    "print(parsed)"
   ],
   "id": "151b3e28591ed962",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "b4014013d39e4aee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "f7e2556e71401af6",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
